% -*- mode: noweb; noweb-default-code-mode: R-mode; -*-
%\VignetteIndexEntry{PIMs as classical distribution free tests}
%\VignetteKeyword{probabilistic index model, distribution, legacy}
%\VignetteDepends{pim}
%\VignettePackage{pim}
%documentclass[12pt, a4paper]{article}
\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage[authoryear,round]{natbib}
\usepackage[utf8]{inputenc}

 
\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\prob}[1]{\text{P}\left\{#1\right\}}
\newcommand{\hatprob}[1]{\hat{\text{P}}\left\{#1\right\}}
\newcommand{\I}[1]{\text{I}\left\{#1\right\}}
\newcommand{\leqs}{\preccurlyeq}



\author{Nick Sabbe}
\usepackage{Sweave}
\begin{document}
\input{pim.legacy-concordance}
\title{PIMs as classical distribution free tests}

\maketitle
\tableofcontents
\section{Introduction}

While \cite{Thas2012} introduces PIMs, they were shown to be extensions of the known distribution free tests, like Wilcoxon in TODO:rankpaperref.

A general estimator for the variance under the null hypothesis has been created ($varianceestimator.H0$), but for these special cases, some simplified formulas exist, which have been provided through the $simplified*$ set of functions.

For each of the code sections below, it is easily checked that the simplified formulas give the same result as the generic code, and that the 
links between the known distribution free tests and PIM are confirmed.

The code also (on the final line of each block) the classical.test function that has been provided. This function uses the PIM to calculate the 
matching test statistic. The advantage (although not shown in this vignette) is that another way of calculating the (co)variances can be specified.
In particular, and as indicated in TODO ref rankpaper, the varianceestimator.sandwich can be passed along to get Wald-style tests for the same
null hypotheses.

\section{Wilcoxon-Mann-Whitney}\label{S_WMW}

Code to check the equivalence (note this includes a legacy implementation):
\begin{Schunk}
\begin{Sinput}
> 	library(pim)
> 	set.seed(1)
> 	wmw1<-demo.WilcoxonMannWhitney()
> 	wmw1$pim2<-pim(y~F(x)-1, data=wmw1$dta, link="identity", poset=lexiposet, 
+ 								 varianceestimator=varianceestimator.H0(), keep.data=TRUE, verbosity=0, 
+ 								 interpretation="regular")
> 	wmw1$pim2
\end{Sinput}
\begin{Soutput}
Call:
pim(formula = y ~ F(x) - 1, data = wmw1$dta, link = "identity", 
    poset = lexiposet, interpretation = "regular", varianceestimator = varianceestimator.H0(), 
    keep.data = TRUE, verbosity = 0)

Coefficients:
x_L_R_1_2 
0.7937182 
\end{Soutput}
\begin{Sinput}
> 	#Simplified formulas
> 	simplifiedpimestimation.pairwisecoefficients(wmw1$dta, out="y", group="x")$beta
\end{Sinput}
\begin{Soutput}
[1] 0.7937182
\end{Soutput}
\begin{Sinput}
> 	simplifiedpimestimation.pairwisecovariance(wmw1$dta, out="y", group="x")
\end{Sinput}
\begin{Soutput}
            1 - 2
1 - 2 0.003572439
\end{Soutput}
\begin{Sinput}
> 	#From applying generic code:
> 	wmw1$pim2$coefficients
\end{Sinput}
\begin{Soutput}
x_L_R_1_2 
0.7937182 
\end{Soutput}
\begin{Sinput}
> 	wmw1$pim2$vcov[1,1]
\end{Sinput}
\begin{Soutput}
[1] 0.003572439
\end{Soutput}
\begin{Sinput}
> 	#Standardized WMW based on wilcoxon test
> 	wmw1$legacy<-legacy.WilcoxonMannWhitney(data=wmw1$dta, out="y", group="x")
> 	wmw1$legacy$statistic
\end{Sinput}
\begin{Soutput}
       W 
-4.91415 
\end{Soutput}
\begin{Sinput}
> 	wmw1$legacy$conversion(wmw1$pim2$coefficients, wmw1$pim2$vcov)
\end{Sinput}
\begin{Soutput}
x_L_R_1_2 
  4.91415 
\end{Soutput}
\begin{Sinput}
> 	classical.test(test="WilcoxonMannWhitney", data=wmw1$dta, out="y", group="x")$statistic
\end{Sinput}
\begin{Soutput}
x_L_R_1_2 
  4.91415 
\end{Soutput}
\end{Schunk}

\section{Kruskal-Wallis}\label{S_KW}

Code to check the equivalence (note this includes a legacy implementation):
\begin{Schunk}
\begin{Sinput}
> 	kw1<-demo.KruskalWallis()
> 	kw1$pim3<-pim(y~F(x)-1, data=kw1$dta, link="identity", poset=fullposet, interpretation="marginal", 
+ 								varianceestimator=varianceestimator.H0(), keep.data=TRUE, verbosity=0)
> 	kw1$pim3
\end{Sinput}
\begin{Soutput}
Call:
pim(formula = y ~ F(x) - 1, data = kw1$dta, link = "identity", 
    poset = fullposet, interpretation = "marginal", varianceestimator = varianceestimator.H0(), 
    keep.data = TRUE, verbosity = 0)

Coefficients:
    x_R_1     x_R_2     x_R_3 
0.2480435 0.4335366 0.7366667 
\end{Soutput}
\begin{Sinput}
> 	#Simplified formulas (lemma 1)
> 	simplifiedpimestimation.marginalcoefficients(kw1$dta, out="y", group="x")
\end{Sinput}
\begin{Soutput}
        1         2         3 
0.2480435 0.4335366 0.7366667 
\end{Soutput}
\begin{Sinput}
> 	simplifiedpimestimation.marginalcovariance(kw1$dta, out="y", group="x")
\end{Sinput}
\begin{Soutput}
              1             2             3
1  0.0028177536 -0.0008416667 -0.0008416667
2 -0.0008416667  0.0012111789 -0.0008416667
3 -0.0008416667 -0.0008416667  0.0014962963
\end{Soutput}
\begin{Sinput}
> 	#From applying generic code:
> 	kw1$pim3$coefficients
\end{Sinput}
\begin{Soutput}
    x_R_1     x_R_2     x_R_3 
0.2480435 0.4335366 0.7366667 
\end{Soutput}
\begin{Sinput}
> 	kw1$pim3$vcov
\end{Sinput}
\begin{Soutput}
              x_R_1         x_R_2         x_R_3
x_R_1  0.0028177536 -0.0008416667 -0.0008416667
x_R_2 -0.0008416667  0.0012111789 -0.0008416667
x_R_3 -0.0008416667 -0.0008416667  0.0014962963
\end{Soutput}
\begin{Sinput}
> 	#Standardized KW based on Kruskal-Wallis test
> 	kw1$legacy<-legacy.KruskalWallis(data=kw1$dta, out="y", group="x")
> 	kw1$legacy$statistic
\end{Sinput}
\begin{Soutput}
Kruskal-Wallis chi-squared 
                  43.45664 
\end{Soutput}
\begin{Sinput}
> 	kw1$legacy$conversion(kw1$pim3$coefficients, kw1$pim3$vcov)
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 43.45664
\end{Soutput}
\begin{Sinput}
> 	classical.test(test="KruskalWallis", data=kw1$dta, out="y", group="x")$statistic
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 43.45664
\end{Soutput}
\end{Schunk}

\section{Mack-Skillings}\label{S_MS}

Code to check the equivalence (note this includes a legacy implementation):
\begin{Schunk}
\begin{Sinput}
> 	mss1<-demo.MackSkillings()
> 	mss1$pim1<-pim(y~F(x)-1, data=mss1$dta, link="identity", blocking.variables="b", 
+ 								 poset=fullposet, interpretation="marginal", 
+ 								 varianceestimator=varianceestimator.H0(), keep.data=TRUE, verbosity=0)
> 	mss1$pim1
\end{Sinput}
\begin{Soutput}
Call:
pim(formula = y ~ F(x) - 1, data = mss1$dta, link = "identity", 
    blocking.variables = "b", poset = fullposet, interpretation = "marginal", 
    varianceestimator = varianceestimator.H0(), keep.data = TRUE, 
    verbosity = 0)

Coefficients:
    x_R_1     x_R_2     x_R_3 
0.2800000 0.5308333 0.6891667 
\end{Soutput}
\begin{Sinput}
> 	#Simplified formulas (lemma 4)
> 	simplifiedpimestimation.marginalcoefficients(mss1$dta, out="y", group="x", block="b")
\end{Sinput}
\begin{Soutput}
        1         2         3 
0.2800000 0.5308333 0.6891667 
\end{Soutput}
\begin{Sinput}
> 	simplifiedpimestimation.marginalcovariance(mss1$dta, out="y", group="x", block="b")
\end{Sinput}
\begin{Soutput}
              1             2             3
1  0.0014351852 -0.0007175926 -0.0007175926
2 -0.0007175926  0.0014351852 -0.0007175926
3 -0.0007175926 -0.0007175926  0.0014351852
\end{Soutput}
\begin{Sinput}
> 	#From applying generic code:
> 	mss1$pim1$coefficients
\end{Sinput}
\begin{Soutput}
    x_R_1     x_R_2     x_R_3 
0.2800000 0.5308333 0.6891667 
\end{Soutput}
\begin{Sinput}
> 	mss1$pim1$vcov
\end{Sinput}
\begin{Soutput}
              x_R_1         x_R_2         x_R_3
x_R_1  0.0014351852 -0.0007175926 -0.0007175926
x_R_2 -0.0007175926  0.0014351852 -0.0007175926
x_R_3 -0.0007175926 -0.0007175926  0.0014351852
\end{Soutput}
\begin{Sinput}
> 	#Standardized MS based on Mack-Skillings test
> 	mss1$legacy<-legacy.MackSkillings(data=mss1$dta, out="y", group="x", block="b")
> 	mss1$legacy$statistic
\end{Sinput}
\begin{Soutput}
[1] 39.54645
\end{Soutput}
\begin{Sinput}
> 	mss1$legacy$conversion(mss1$pim1$coefficients, mss1$pim1$vcov)
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 39.54645
\end{Soutput}
\begin{Sinput}
> 	classical.test(test="MackSkillings", data=mss1$dta, out="y", group="x", block="b")$statistic
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 39.54645
\end{Soutput}
\end{Schunk}

\section{Brown-Hettmansperger}\label{S_BH}

Code to check the equivalence (note this includes a legacy implementation):
\begin{Schunk}
\begin{Sinput}
> 	bh1<-demo.BrownHettmansperger()
> 	bh1$pim1<-pim(y~F(x)-1, data=bh1$dta, link="identity", poset=fullposet, 
+ 								varianceestimator=varianceestimator.H0(), keep.data=TRUE, verbosity=0, 
+ 								interpretation="regular")
> 	bh1$pim1
\end{Sinput}
\begin{Soutput}
Call:
pim(formula = y ~ F(x) - 1, data = bh1$dta, link = "identity", 
    poset = fullposet, interpretation = "regular", varianceestimator = varianceestimator.H0(), 
    keep.data = TRUE, verbosity = 0)

Coefficients:
x_L_R_1_2 x_L_R_1_3 x_L_R_2_3 
0.8278867 0.8936652 0.7264957 
\end{Soutput}
\begin{Sinput}
> 	#Simplified formulas (lemma 4)
> 	simplifiedpimestimation.pairwisecoefficients(bh1$dta, out="y", group="x")$beta
\end{Sinput}
\begin{Soutput}
[1] 0.8278867 0.8936652 0.7264957
\end{Soutput}
\begin{Sinput}
> 	simplifiedpimestimation.pairwisecovariance(bh1$dta, out="y", group="x")
\end{Sinput}
\begin{Soutput}
             1 - 2       1 - 3        2 - 3
1 - 2  0.005628177 0.002450980 -0.003086420
1 - 3  0.002450980 0.004650578  0.002136752
2 - 3 -0.003086420 0.002136752  0.005302311
\end{Soutput}
\begin{Sinput}
> 	#From applying generic code:
> 	bh1$pim1$coefficients
\end{Sinput}
\begin{Soutput}
x_L_R_1_2 x_L_R_1_3 x_L_R_2_3 
0.8278867 0.8936652 0.7264957 
\end{Soutput}
\begin{Sinput}
> 	bh1$pim1$vcov
\end{Sinput}
\begin{Soutput}
             x_L_R_1_2   x_L_R_1_3    x_L_R_2_3
x_L_R_1_2  0.005628177 0.002450980 -0.003086420
x_L_R_1_3  0.002450980 0.004650578  0.002136752
x_L_R_2_3 -0.003086420 0.002136752  0.005302311
\end{Soutput}
\begin{Sinput}
> 	#Standardized BH based on Brown-Hettmansperger test
> 	bh1$legacy<-legacy.BrownHettmansperger(data=bh1$dta, out="y", group="x")
> 	bh1$legacy$statistic
\end{Sinput}
\begin{Soutput}
Kruskal-Wallis chi-squared 
                  152.4325 
\end{Soutput}
\begin{Sinput}
> 	bh1$legacy$conversion(bh1$pim1$coefficients, bh1$pim1$vcov)
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 152.4325
\end{Soutput}
\begin{Sinput}
> 	classical.test(test="BrownHettmansperger", data=bh1$dta, out="y", group="x")$statistic
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 152.4325
\end{Soutput}
\end{Schunk}

\section{Jonckheere-Terpstra}\label{S_JT}

Code to check the equivalence (note this includes a legacy implementation):
\begin{Schunk}
\begin{Sinput}
> 	jt1<-demo.JonckheereTerpstra(force.balanced=FALSE)
> 	jt1$pim1<-pim(y~F(x)-1, data=jt1$dta, link="identity", poset=lexiposet, 
+ 								varianceestimator=varianceestimator.H0(), keep.data=TRUE, verbosity=0, 
+ 								interpretation="regular")
> 	jt1$pim1
\end{Sinput}
\begin{Soutput}
Call:
pim(formula = y ~ F(x) - 1, data = jt1$dta, link = "identity", 
    poset = lexiposet, interpretation = "regular", varianceestimator = varianceestimator.H0(), 
    keep.data = TRUE, verbosity = 0)

Coefficients:
x_L_R_1_2 x_L_R_1_3 x_L_R_1_4 x_L_R_2_3 x_L_R_2_4 x_L_R_3_4 
0.7925926 0.9025641 0.9916667 0.7065527 0.9733796 0.9314904 
\end{Soutput}
\begin{Sinput}
> 	#Simplified formulas (lemma 4)
> 	simplifiedpimestimation.pairwisecoefficients(jt1$dta, out="y", group="x")$beta
\end{Sinput}
\begin{Soutput}
[1] 0.7925926 0.9025641 0.9916667 0.7065527 0.9733796 0.9314904
\end{Soutput}
\begin{Sinput}
> 	simplifiedpimestimation.pairwisecovariance(jt1$dta, out="y", group="x")
\end{Sinput}
\begin{Soutput}
             1 - 2        1 - 3       1 - 4        2 - 3        2 - 4
1 - 2  0.008847737  0.005555556 0.005555556 -0.003086420 -0.003086420
1 - 3  0.005555556  0.008974359 0.005555556  0.003205128  0.000000000
1 - 4  0.005555556  0.005555556 0.008333333  0.000000000  0.002604167
2 - 3 -0.003086420  0.003205128 0.000000000  0.006410256  0.003086420
2 - 4 -0.003086420  0.000000000 0.002604167  0.003086420  0.005787037
3 - 4  0.000000000 -0.003205128 0.002604167 -0.003205128  0.002604167
             3 - 4
1 - 2  0.000000000
1 - 3 -0.003205128
1 - 4  0.002604167
2 - 3 -0.003205128
2 - 4  0.002604167
3 - 4  0.005909455
\end{Soutput}
\begin{Sinput}
> 	#From applying generic code:
> 	jt1$pim1$coefficients
\end{Sinput}
\begin{Soutput}
x_L_R_1_2 x_L_R_1_3 x_L_R_1_4 x_L_R_2_3 x_L_R_2_4 x_L_R_3_4 
0.7925926 0.9025641 0.9916667 0.7065527 0.9733796 0.9314904 
\end{Soutput}
\begin{Sinput}
> 	jt1$pim1$vcov
\end{Sinput}
\begin{Soutput}
             x_L_R_1_2    x_L_R_1_3   x_L_R_1_4    x_L_R_2_3    x_L_R_2_4
x_L_R_1_2  0.008847737  0.005555556 0.005555556 -0.003086420 -0.003086420
x_L_R_1_3  0.005555556  0.008974359 0.005555556  0.003205128  0.000000000
x_L_R_1_4  0.005555556  0.005555556 0.008333333  0.000000000  0.002604167
x_L_R_2_3 -0.003086420  0.003205128 0.000000000  0.006410256  0.003086420
x_L_R_2_4 -0.003086420  0.000000000 0.002604167  0.003086420  0.005787037
x_L_R_3_4  0.000000000 -0.003205128 0.002604167 -0.003205128  0.002604167
             x_L_R_3_4
x_L_R_1_2  0.000000000
x_L_R_1_3 -0.003205128
x_L_R_1_4  0.002604167
x_L_R_2_3 -0.003205128
x_L_R_2_4  0.002604167
x_L_R_3_4  0.005909455
\end{Soutput}
\begin{Sinput}
> 	#Standardized JT based on Jonckheere-Terpstra test
> 	jt1$legacy<-legacy.JonckheereTerpstra(data=jt1$dta, out="y", group="x", verbosity=1) 
\end{Sinput}
\begin{Soutput}
mu: 1836.5 
sigsq: 26044.92 
mainterm: 3261 
\end{Soutput}
\begin{Sinput}
> 	jt1$legacy$statistic
\end{Sinput}
\begin{Soutput}
[1] 8.826753
\end{Soutput}
\begin{Sinput}
> 	jt1$legacy$conversion(jt1$pim1$coefficients, jt1$pim1$vcov)
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 8.826753
\end{Soutput}
\begin{Sinput}
> 	classical.test(test="JonckheereTerpstra", data=jt1$dta, out="y", group="x")$statistic
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 8.826753
\end{Soutput}
\end{Schunk}

\section{Mack-Wolfe}\label{S_MW}

Code to check the equivalence (note this includes a legacy implementation):
\begin{Schunk}
\begin{Sinput}
> 	mw1<-demo.MackWolfe(force.balanced=FALSE)
> 	mw1$pim1<-pim(y~F(x)-1, data=mw1$dta, link="identity", poset=lexiposet, 
+ 								varianceestimator=varianceestimator.H0(), keep.data=TRUE, verbosity=0, 
+ 								interpretation="regular")
> 	mw1$pim1
\end{Sinput}
\begin{Soutput}
Call:
pim(formula = y ~ F(x) - 1, data = mw1$dta, link = "identity", 
    poset = lexiposet, interpretation = "regular", varianceestimator = varianceestimator.H0(), 
    keep.data = TRUE, verbosity = 0)

Coefficients:
 x_L_R_1_2  x_L_R_1_3  x_L_R_1_4  x_L_R_2_3  x_L_R_2_4  x_L_R_3_4 
0.71726190 1.00000000 0.91904762 0.99621212 0.73333333 0.01414141 
\end{Soutput}
\begin{Sinput}
> 	#Simplified formulas (lemma 4)
> 	simplifiedpimestimation.pairwisecoefficients(mw1$dta, out="y", group="x")$beta
\end{Sinput}
\begin{Soutput}
[1] 0.71726190 1.00000000 0.91904762 0.99621212 0.73333333 0.01414141
\end{Soutput}
\begin{Sinput}
> 	simplifiedpimestimation.pairwisecovariance(mw1$dta, out="y", group="x")
\end{Sinput}
\begin{Soutput}
             1 - 2        1 - 3       1 - 4        2 - 3        2 - 4
1 - 2  0.009424603  0.003968254 0.003968254 -0.005208333 -0.005208333
1 - 3  0.003968254  0.006613757 0.003968254  0.002525253  0.000000000
1 - 4  0.003968254  0.003968254 0.006878307  0.000000000  0.002777778
2 - 3 -0.005208333  0.002525253 0.000000000  0.007891414  0.005208333
2 - 4 -0.005208333  0.000000000 0.002777778  0.005208333  0.008159722
3 - 4  0.000000000 -0.002525253 0.002777778 -0.002525253  0.002777778
             3 - 4
1 - 2  0.000000000
1 - 3 -0.002525253
1 - 4  0.002777778
2 - 3 -0.002525253
2 - 4  0.002777778
3 - 4  0.005387205
\end{Soutput}
\begin{Sinput}
> 	#From applying generic code:
> 	mw1$pim1$coefficients
\end{Sinput}
\begin{Soutput}
 x_L_R_1_2  x_L_R_1_3  x_L_R_1_4  x_L_R_2_3  x_L_R_2_4  x_L_R_3_4 
0.71726190 1.00000000 0.91904762 0.99621212 0.73333333 0.01414141 
\end{Soutput}
\begin{Sinput}
> 	mw1$pim1$vcov
\end{Sinput}
\begin{Soutput}
             x_L_R_1_2    x_L_R_1_3   x_L_R_1_4    x_L_R_2_3    x_L_R_2_4
x_L_R_1_2  0.009424603  0.003968254 0.003968254 -0.005208333 -0.005208333
x_L_R_1_3  0.003968254  0.006613757 0.003968254  0.002525253  0.000000000
x_L_R_1_4  0.003968254  0.003968254 0.006878307  0.000000000  0.002777778
x_L_R_2_3 -0.005208333  0.002525253 0.000000000  0.007891414  0.005208333
x_L_R_2_4 -0.005208333  0.000000000 0.002777778  0.005208333  0.008159722
x_L_R_3_4  0.000000000 -0.002525253 0.002777778 -0.002525253  0.002777778
             x_L_R_3_4
x_L_R_1_2  0.000000000
x_L_R_1_3 -0.002525253
x_L_R_1_4  0.002777778
x_L_R_2_3 -0.002525253
x_L_R_2_4  0.002777778
x_L_R_3_4  0.005387205
\end{Soutput}
\begin{Sinput}
> 	#Standardized MW based on Mack-Wolfe test
> 	mw1$legacy<-legacy.MackWolfe(data=mw1$dta, out="y", group="x", 
+ 															 levelP=as.character(which.max(mw1$groupmeans)), verbosity=1)
\end{Sinput}
\begin{Soutput}
mu: 1273.5 
sigsq: 19673.25 
leftterm: 1460 
rightterm: 976 
\end{Soutput}
\begin{Sinput}
> 	mw1$legacy$statistic
\end{Sinput}
\begin{Soutput}
[1] 8.288099
\end{Soutput}
\begin{Sinput}
> 	mw1$legacy$conversion(mw1$pim1$coefficients, mw1$pim1$vcov)
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 8.288099
\end{Soutput}
\begin{Sinput}
> 	classical.test(test="MackWolfe", data=mw1$dta, out="y", group="x",
+ 								 levelP=as.character(which.max(mw1$groupmeans)))$statistic
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 8.288099
\end{Soutput}
\end{Schunk}

\bibliographystyle{plainnat}
\bibliography{jdeneve}

\end{document}
